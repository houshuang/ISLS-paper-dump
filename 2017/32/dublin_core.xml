<?xml version="1.0" encoding="utf-8" standalone="no"?>
    <dublin_core schema="dc">
    <dcvalue element="contributor" qualifier="author">Gutu, Gabriel</dcvalue>
<dcvalue element="contributor" qualifier="author">Dascalu, Mihai</dcvalue>
<dcvalue element="contributor" qualifier="author">Rebedea, Traian</dcvalue>
<dcvalue element="contributor" qualifier="author">Trausan-Matu, Stefan</dcvalue>
      <dcvalue element="date" qualifier="accessioned">2017-06-19T10:50:27Z</dcvalue>
      <dcvalue element="date" qualifier="available">2017-06-19T10:50:27Z</dcvalue>
      <dcvalue element="date" qualifier="issued">2017-07</dcvalue>
      <dcvalue element="identifier" qualifier="citation" language="en_US">Gutu, G., Dascalu, M., Rebedea, T., &amp; Trausan-Matu, S.&#x20;(2017).&#x20;Time and Semantic Similarity – What is the Best Alternative to Capture Implicit Links in CSCL Conversations?&#x20;In&#x20;Smith,&#x20;B.&#x20;K.,&#x20;Borge,&#x20;M.,&#x20;Mercier,&#x20;E.,&#x20;and&#x20;Lim,&#x20;K.&#x20;Y.&#x20;(Eds.).&#x20;(2017).&#x20;Making&#x20;a&#x20;Difference:&#x20;Prioritizing&#x20;Equity&#x20;and&#x20;Access&#x20;in&#x20;CSCL,&#x20;12th&#x20;International&#x20;Conference&#x20;on&#x20;Computer&#x20;Supported&#x20;Collaborative&#x20;Learning&#x20;(CSCL)&#x20;2017,&#x20;Volume&#x20;1.&#x20;Philadelphia,&#x20;PA:&#x20;International&#x20;Society&#x20;of&#x20;the&#x20;Learning&#x20;Sciences.</dcvalue>
      <dcvalue element="identifier" qualifier="uri">https:dx.doi.org&#x2F;10.22318&#x2F;cscl2017.32</dcvalue>
      <dcvalue element="description" qualifier="abstract" language="en_US">The goal of our research is to compare novel semantic techniques for identifying implicit links between utterances in multi-participant CSCL chat conversations. Cohesion, reflected by the strength of the semantic relations behind the automatically identified links, is assessed using WordNet-based semantic distances, as well as unsupervised semantic models, i.e. Latent Semantic Analysis (LSA) and Latent Dirichlet Allocation (LDA). The analysis is built on top of the ReaderBench framework and multiple identification heuristics were compared, including: semantic cohesion metrics, normalized cohesion measures and Mihalcea’s formula. A corpus of 55 conversations in which participants used explicit links between utterances where they considered necessary for clarity was used for validation. Our study represents an in-depth analysis of multiple methods used to identify implicit links and reveals the accuracy of each technique in terms of capturing the explicit references made by users. Statistical similarity measures ensured the best overall identification accuracy when using Mihalcea’s formula, while WordNet-based techniques provided best results for un-normalized similarity scores applied on a window of 5 utterances and a time frame of 1 minute.</dcvalue>
      <dcvalue element="language" qualifier="iso" language="en_US">en</dcvalue>
      <dcvalue element="publisher" qualifier="none" language="en_US">Philadelphia,&#x20;PA:&#x20;International&#x20;Society&#x20;of&#x20;the&#x20;Learning&#x20;Sciences.</dcvalue>
      <dcvalue element="title" qualifier="none" language="en_US">Time and Semantic Similarity – What is the Best Alternative to Capture Implicit Links in CSCL Conversations?</dcvalue>
      <dcvalue element="type" qualifier="none" language="en_US">Book&#x20;chapter</dcvalue>
      <dc:subject xml:lang="en">Learning Analytics / Educational Data Mining</dc:subject>
<dc:subject xml:lang="en">Learning Management Systems</dc:subject>
<dc:subject xml:lang="en">Education Technology</dc:subject>
<dc:subject xml:lang="en">Community Building</dc:subject>
    </dublin_core>